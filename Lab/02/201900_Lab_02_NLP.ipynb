{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1. Naive Bayes:\n","   - Naive Bayes is based on Bayes' theorem, which calculates the probability of a class given some features using conditional probability.\n","   - The \"naive\" assumption is that all features are independent given the class label.\n","   - Formula:\n","     P(y|x_1, x_2, ..., x_n) = (P(y) * P(x_1|y) * P(x_2|y) * ... * P(x_n|y)) / (P(x_1) * P(x_2) * ... * P(x_n))\n","\n","2. Log Likelihood:\n","   - Likelihood is the probability of the observed data given a model.\n","   - Log likelihood is the logarithm of the likelihood function.\n","   - It's often used in maximum likelihood estimation.\n","   - Formula depends on the model; for example, in linear regression:\n","     log L(θ|y) = -(n/2) * log(2πσ^2) - (1/(2σ^2)) * Σ(y_i - θx_i)^2\n"],"metadata":{"id":"H_tl-H45xk09"}},{"cell_type":"markdown","source":["### 1. Import Functions and Data"],"metadata":{"id":"VJxUeHnobMGX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7kv4Gd5QPcN","outputId":"55fdbc8b-1988-425a-9366-e1255429178f","executionInfo":{"status":"ok","timestamp":1714476436039,"user_tz":-300,"elapsed":3785,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/twitter_samples.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["\n","import nltk # Python library for NLP\n","from nltk.corpus import twitter_samples # sample Twitter dataset from NLTK\n","import matplotlib.pyplot as plt # library for visualization\n","import random # pseudo-random number generator\n","\n","import re # library for regular expression operations\n","import string # for string operations\n","\n","from nltk.corpus import stopwords # module for stop words that come with NLTK\n","from nltk.stem import PorterStemmer # module for stemming\n","from nltk.tokenize import TweetTokenizer # module for tokenizing strings\n","\n","import csv\n","import numpy as np\n","import pandas as pd\n","from sklearn.utils import shuffle\n","\n","nltk.download('twitter_samples')\n","nltk.download('stopwords')\n"]},{"cell_type":"code","source":["\n","# select the set of positive and negative tweets\n","all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n","all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n","\n","# Save the tweets to a file\n","with open('positive_tweets.txt', 'w', encoding='utf-8') as f:\n","    f.write('\\n'.join(all_positive_tweets))\n","\n","with open('negative_tweets.txt', 'w', encoding='utf-8') as f:\n","    f.write('\\n'.join(all_negative_tweets))\n"],"metadata":{"id":"GZRStDw9Rc6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Randomly select three positive tweets\n","random_positive_tweets = random.sample(all_positive_tweets, 3)\n","\n","# Randomly select three negative tweets\n","random_negative_tweets = random.sample(all_negative_tweets, 3)\n","\n","print(\"Randomly selected positive tweets:\")\n","for tweet in random_positive_tweets:\n","    print(tweet)\n","\n","print(\"\\nRandomly selected negative tweets:\")\n","for tweet in random_negative_tweets:\n","    print(tweet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFd2nSubZu5U","outputId":"3f6a7074-2a11-4ee2-d172-27ad80146f2e","executionInfo":{"status":"ok","timestamp":1714476437395,"user_tz":-300,"elapsed":11,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Randomly selected positive tweets:\n","@lorainekateyumi  follow @jnlazts &amp; http://t.co/RCvcYYO0Iq follow u back :)\n","@_sunshinehoran_ happy birthday love :)\n","\"@zaynmalik just had a dinner with my love @Real_Liam_Payne love you babe ! :) x\"\n","\n","Randomly selected negative tweets:\n","@NiaLovelis i miss you :(\n","pls follow me http://t.co/stdLTH1PBS\n","UGH :( I THOUGHT... @camerondallas http://t.co/KrrqH4aRbw\n","@alyaeldeeb12345 we're all in the same feelings :( http://t.co/lzd4XIo3aM\n"]}]},{"cell_type":"code","source":["\n","print(len(all_positive_tweets),all_positive_tweets[0])\n","print(len(all_negative_tweets),all_negative_tweets[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsLCfNhNRqYV","outputId":"8d9c719c-442b-45f5-ffe4-93e77124eda4","executionInfo":{"status":"ok","timestamp":1714476437395,"user_tz":-300,"elapsed":6,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5000 #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n","5000 hopeless for tmr :(\n"]}]},{"cell_type":"markdown","source":["### 2. Preprocessing"],"metadata":{"id":"0jHBlwOtWOwi"}},{"cell_type":"code","source":["\n","def process_tweet(tweet):\n","\n","  \"\"\"Process tweet function.\n","  Input:\n","  tweet: a string containing a tweet\n","  Output:\n","  tweets_clean: a list of words containing the processed tweet\n","  \"\"\"\n","  stemmer = PorterStemmer( )\n","  stopwords_english = stopwords.words('english')\n","  # remove stock market tickers like $GE\n","  tweet = re.sub(r'\\$\\w*', '', tweet)\n","  # remove old style retweet text \"RT\"\n","  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n","  # remove hyperlinks\n","  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n","\n","  # only removing the hash # sign from the word\n","  tweet = re.sub(r'#', '', tweet)\n","  # tokenize tweets\n","  tokenizer = TweetTokenizer(preserve_case=False,\n","  strip_handles=True, reduce_len=True)\n","\n","  tweet_tokens = tokenizer.tokenize(tweet)\n","\n","  tweets_clean = []\n","  for word in tweet_tokens:\n","    if (word not in stopwords_english and # remove stopwords\n","      word not in string.punctuation): # remove punctuation\n","\n","      # tweets_clean.append(word)\n","      stem_word = stemmer.stem(word) # stemming word\n","      tweets_clean.append(stem_word)\n","\n","  return tweets_clean"],"metadata":{"id":"r4cMKFzkZJUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Initializing lists to store processed positive and negative tweets\n","pro_pos_tw = []\n","pro_neg_tw = []\n","\n","# Processing each tweet in the list of positive tweets\n","for tweet in all_positive_tweets:\n","    # Applying the process_tweet function to preprocess the tweet\n","    pro_pos_tw.append(process_tweet(tweet))\n","\n","# Processing each tweet in the list of negative tweets\n","for tweet in all_negative_tweets:\n","    # Applying the process_tweet function to preprocess the tweet\n","    pro_neg_tw.append(process_tweet(tweet))\n","\n","# Printing the number of processed positive tweets and an example of the first processed positive tweet\n","print(\"Number of processed positive tweets:\", len(pro_pos_tw))\n","print(\"Example of a processed positive tweet:\", pro_pos_tw[0])\n","\n","# Printing the number of processed negative tweets and an example of the first processed negative tweet\n","print(\"Number of processed negative tweets:\", len(pro_neg_tw))\n","print(\"Example of a processed negative tweet:\", pro_neg_tw[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JN319jpSwq-","outputId":"3c9ca1d4-5391-4a75-fb60-eb845bae42dc","executionInfo":{"status":"ok","timestamp":1714476452355,"user_tz":-300,"elapsed":14963,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of processed positive tweets: 5000\n","Example of a processed positive tweet: ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n","Number of processed negative tweets: 5000\n","Example of a processed negative tweet: ['hopeless', 'tmr', ':(']\n"]}]},{"cell_type":"code","source":["\n","# Shuffle positive and negative tweets\n","random.shuffle(pro_pos_tw)\n","random.shuffle(pro_neg_tw)\n","\n","# Select 4000 random positive and negative tweets for training\n","train_pos_tw = pro_pos_tw[:4000]\n","train_neg_tw = pro_neg_tw[:4000]\n","\n","# Select 1000 random positive and negative tweets for testing\n","test_pos_tw = pro_pos_tw[4000:]\n","test_neg_tw = pro_neg_tw[4000:]\n","\n","# Combine training and testing tweets\n","train_tweets = train_pos_tw + train_neg_tw\n","test_tweets = test_pos_tw + test_neg_tw\n","\n","# Create labels\n","train_labels = [1] * len(train_pos_tw) + [0] * len(train_neg_tw)\n","test_labels = [1] * len(test_pos_tw) + [0] * len(test_neg_tw)\n","\n","# Checking sizes of training and testing sets\n","print(\"Training set size:\", len(train_tweets))\n","print(\"Testing set size:\", len(test_tweets))\n","\n","# Checking distribution of labels in training and testing sets\n","from collections import Counter\n","print(\"Training set label distribution:\", Counter(train_labels))\n","print(\"Testing set label distribution:\", Counter(test_labels))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlegA9GlUbGo","outputId":"81650674-9493-4cd0-9de9-d3198f413243","executionInfo":{"status":"ok","timestamp":1714476452356,"user_tz":-300,"elapsed":26,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set size: 8000\n","Testing set size: 2000\n","Training set label distribution: Counter({1: 4000, 0: 4000})\n","Testing set label distribution: Counter({1: 1000, 0: 1000})\n"]}]},{"cell_type":"code","source":["len(train_tweets),len(train_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rh4j3H1AqcYm","outputId":"2a4e7e84-b894-4734-8ee4-c33a422f9a1f","executionInfo":{"status":"ok","timestamp":1714476452356,"user_tz":-300,"elapsed":21,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8000, 8000)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["\n","print(train_tweets[10])\n","print(train_labels[10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BGWO1HKqem3","outputId":"4958ec9a-e4e9-49c7-ea40-fd46e34fc807","executionInfo":{"status":"ok","timestamp":1714476452357,"user_tz":-300,"elapsed":20,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['hello', ':)', 'get', 'youth', 'job', 'opportun', 'follow']\n","1\n"]}]},{"cell_type":"code","source":["count=0\n","for l,t in zip(train_labels,train_tweets):\n","  print(l,t)\n","\n","  count += 1\n","  if(count>10):\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vecrLl0ZVbgY","outputId":"42e05ea1-3f6d-4aa6-ee7a-6502f47cfcaa","executionInfo":{"status":"ok","timestamp":1714476452357,"user_tz":-300,"elapsed":18,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 ['nice', 'dave', ':d']\n","1 ['okay', 'son', '4:13', 'cant', 'sleep', 'bc', 'insomnia', 'forgot', 'take', 'sleep', 'medic', ':)']\n","1 ['stat', 'week', 'arriv', '1', 'new', 'follow', 'unfollow', ':)', 'via']\n","1 [':)']\n","1 ['see', 'saturday', ':p', \"i'll\", 'see', 'stormi', ':d']\n","1 ['heeeyyy', 'follow', 'fan', 'account', 'thank', ':)']\n","1 ['fun', ':p']\n","1 ['follow']\n","1 ['snapchat', 'sexyjudi', '19', 'snapchat', 'kikmeboy', 'tagsforlik', 'pussi', 'gay', 'indiemus', 'sexo', ':)']\n","1 ['thank', 'mom', ':)']\n","1 ['hello', ':)', 'get', 'youth', 'job', 'opportun', 'follow']\n"]}]},{"cell_type":"markdown","source":["### 3. Extract Feature"],"metadata":{"id":"WPyrn42aa75w"}},{"cell_type":"code","source":["def build_freqs_df(tweets, ys):\n","    \"\"\"\n","    Build frequencies and return as DataFrame.\n","    Input:\n","    tweets: a list of tweets\n","    ys: an m x 1 array with the sentiment label of each tweet\n","    (either 0 or 1)\n","    Output:\n","    df: DataFrame with three columns: 'Word', 'posfreq', and 'negfreq'\n","    \"\"\"\n","    freqs = {}\n","\n","    for y, tweet in zip(ys, tweets):\n","        for word in tweet:\n","            if word not in freqs:\n","                freqs[word] = {'posfreq': 0, 'negfreq': 0}\n","            if y == 1:\n","                freqs[word]['posfreq'] += 1\n","            else:\n","                freqs[word]['negfreq'] += 1\n","\n","    # Convert frequency dictionary to DataFrame\n","    df = pd.DataFrame(freqs.items(), columns=['Word', 'Frequency'])\n","\n","    # Split 'Frequency' dictionary into two columns: 'posfreq' and 'negfreq'\n","    df[['posfreq', 'negfreq']] = pd.DataFrame(df['Frequency'].tolist(), index=df.index)\n","\n","    # Drop 'Frequency' column\n","    df.drop(columns=['Frequency'], inplace=True)\n","\n","    return df"],"metadata":{"id":"2s-D4FcdHs_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["freq = build_freqs_df(train_tweets+test_tweets,train_labels+test_labels)"],"metadata":{"id":"INHUEJtfcWrb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(freq),type(freq),freq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfTmzwfEe3CU","outputId":"23b01baf-fff4-4a6d-c060-0b2cb69edf7a","executionInfo":{"status":"ok","timestamp":1714476452358,"user_tz":-300,"elapsed":15,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10416 <class 'pandas.core.frame.DataFrame'>            Word  posfreq  negfreq\n","0          nice       98       19\n","1          dave        5        0\n","2            :d      629        0\n","3          okay       39       38\n","4           son        4        1\n","...         ...      ...      ...\n","10411     bench        0        1\n","10412   analyst        0        1\n","10413   expedia        0        1\n","10414   bellevu        0        1\n","10415  hard-wir        0        1\n","\n","[10416 rows x 3 columns]\n"]}]},{"cell_type":"code","source":["freq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Ap4EaJSPJHw5","outputId":"4d9f7e6f-a2d2-4286-c465-e026c2c023a1","executionInfo":{"status":"ok","timestamp":1714476452358,"user_tz":-300,"elapsed":13,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Word  posfreq  negfreq\n","0          nice       98       19\n","1          dave        5        0\n","2            :d      629        0\n","3          okay       39       38\n","4           son        4        1\n","...         ...      ...      ...\n","10411     bench        0        1\n","10412   analyst        0        1\n","10413   expedia        0        1\n","10414   bellevu        0        1\n","10415  hard-wir        0        1\n","\n","[10416 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-920d682d-2ae8-427c-8abc-926b3e5b4334\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>posfreq</th>\n","      <th>negfreq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nice</td>\n","      <td>98</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>dave</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>:d</td>\n","      <td>629</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>okay</td>\n","      <td>39</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>son</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10411</th>\n","      <td>bench</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10412</th>\n","      <td>analyst</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10413</th>\n","      <td>expedia</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10414</th>\n","      <td>bellevu</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10415</th>\n","      <td>hard-wir</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10416 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-920d682d-2ae8-427c-8abc-926b3e5b4334')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-920d682d-2ae8-427c-8abc-926b3e5b4334 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-920d682d-2ae8-427c-8abc-926b3e5b4334');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a51c3b13-fe14-4670-a9d5-22be24681422\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a51c3b13-fe14-4670-a9d5-22be24681422')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a51c3b13-fe14-4670-a9d5-22be24681422 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"freq","summary":"{\n  \"name\": \"freq\",\n  \"rows\": 10416,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10416,\n        \"samples\": [\n          \"43\",\n          \"routin\",\n          \"sexyjudi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"posfreq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38,\n        \"min\": 0,\n        \"max\": 3568,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          17,\n          4,\n          238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negfreq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 0,\n        \"max\": 4571,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          123,\n          56,\n          47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def calculate_lambda(df):\n","    \"\"\"\n","    Calculate lambda (λ) values for each row in the dataframe.\n","\n","    Input:\n","    df: pandas DataFrame containing columns 'Positive_Count' and 'Negative_Count'\n","\n","    Output:\n","    df: pandas DataFrame with additional columns 'p(w,pos)', 'p(w,neg)', and 'lambda'\n","    \"\"\"\n","\n","    # Calculate p(w,pos) and p(w,neg)\n","    df['p(w,pos)'] = (df['posfreq'] + 1) / ( len(df) + df['posfreq'].sum() )\n","    df['p(w,neg)'] = (df['negfreq'] + 1) / ( len(df) + df['negfreq'].sum() )\n","\n","    # Calculate lambda (λ)\n","    df['lambda'] = df['p(w,pos)'] / df['p(w,neg)']\n","\n","    return df"],"metadata":{"id":"D9-v8DdO0d_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the function to the training data\n","l_data = calculate_lambda(freq)\n","print(\"Training Data with Lambda Values:\")\n","print(l_data.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pB7d1AX3DuDG","outputId":"4302027e-b86b-464f-dc8a-8470cd63e2ab","executionInfo":{"status":"ok","timestamp":1714476453237,"user_tz":-300,"elapsed":13,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Data with Lambda Values:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10416 entries, 0 to 10415\n","Data columns (total 6 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Word      10416 non-null  object \n"," 1   posfreq   10416 non-null  int64  \n"," 2   negfreq   10416 non-null  int64  \n"," 3   p(w,pos)  10416 non-null  float64\n"," 4   p(w,neg)  10416 non-null  float64\n"," 5   lambda    10416 non-null  float64\n","dtypes: float64(3), int64(2), object(1)\n","memory usage: 488.4+ KB\n","None\n"]}]},{"cell_type":"markdown","source":["### 4. Train"],"metadata":{"id":"VgdDGCEC5dSA"}},{"cell_type":"code","source":["def train_naive_bayes(train_x):\n","    '''\n","    Input:\n","        train_x: pandas DataFrame containing columns 'Word', 'Positive_Count', 'Negative_Count', 'p(w,pos)', 'p(w,neg)', and 'lambda'\n","    Output:\n","        logprior: the log prior.\n","        train_x: pandas DataFrame with the log likelihood column added\n","    '''\n","    # Fill missing lambda values with 0\n","    train_x['lambda'].fillna(0, inplace=True)\n","    train_x['lambda'].replace([np.inf, -np.inf], 0, inplace=True)\n","\n","    # Calculate log likelihood for each word\n","    train_x['log_likelihood'] = np.log(train_x['lambda'])\n","\n","    logprior = 0  # Not sure if this is intended for Naive Bayes, since usually there's no logprior in the training phase.\n","\n","    return logprior, train_x"],"metadata":{"id":"3DGhpjuP4U-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logprior, lldata = train_naive_bayes(l_data)\n","print(logprior)\n","print(len(lldata))"],"metadata":{"id":"h3nGAwmd4bmU","outputId":"a4f11bf3-0b5a-4f7b-f56d-ab329da2b365","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714476453237,"user_tz":-300,"elapsed":12,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","10416\n"]}]},{"cell_type":"code","source":["print(lldata)"],"metadata":{"id":"-tjlotZ9Aprz","outputId":"d19f7171-0034-4241-94d7-7a65ebcb97f2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714476453237,"user_tz":-300,"elapsed":10,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           Word  posfreq  negfreq  p(w,pos)  p(w,neg)      lambda  \\\n","0          nice       98       19  0.002239  0.000453    4.938244   \n","1          dave        5        0  0.000136  0.000023    5.985750   \n","2            :d      629        0  0.014250  0.000023  628.503766   \n","3          okay       39       38  0.000905  0.000884    1.023205   \n","4           son        4        1  0.000113  0.000045    2.494063   \n","...         ...      ...      ...       ...       ...         ...   \n","10411     bench        0        1  0.000023  0.000045    0.498813   \n","10412   analyst        0        1  0.000023  0.000045    0.498813   \n","10413   expedia        0        1  0.000023  0.000045    0.498813   \n","10414   bellevu        0        1  0.000023  0.000045    0.498813   \n","10415  hard-wir        0        1  0.000023  0.000045    0.498813   \n","\n","       log_likelihood  \n","0            1.597010  \n","1            1.789382  \n","2            6.443342  \n","3            0.022940  \n","4            0.913913  \n","...               ...  \n","10411       -0.695525  \n","10412       -0.695525  \n","10413       -0.695525  \n","10414       -0.695525  \n","10415       -0.695525  \n","\n","[10416 rows x 7 columns]\n"]}]},{"cell_type":"markdown","source":["### 5. Test"],"metadata":{"id":"z4UT3YMrNp4j"}},{"cell_type":"code","source":["test_tweets[:10]"],"metadata":{"id":"xAZGbvMRokaX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d47102af-9406-4f78-f670-c2097fce464f","executionInfo":{"status":"ok","timestamp":1714476453237,"user_tz":-300,"elapsed":9,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['dear',\n","  'person',\n","  'pleas',\n","  'studi',\n","  'embarrass',\n","  'urself',\n","  'entropi',\n","  'work',\n","  '100',\n","  'w',\n","  'evolut',\n","  ':)'],\n"," ['u',\n","  'cant',\n","  'chang',\n","  'peopl',\n","  'feel',\n","  'u',\n","  'dnt',\n","  'tri',\n","  'live',\n","  'ur',\n","  'life',\n","  'happi',\n","  ':)'],\n"," ['stat', 'week', 'arriv', '1', 'new', 'follow', 'unfollow', ':)', 'via'],\n"," ['mom', ':)', 'horror', 'movi'],\n"," ['oley', ':d'],\n"," ['contestkiduniya', 'hope', 'win', ':)'],\n"," ['jummah', 'mubarak', 'rememb', 'prayr', ':)'],\n"," ['done', 'yein', ':)'],\n"," [\"i'm\", 'glad', ':d', 'cri', '__'],\n"," ['need', 'find', 'boy', 'love', 'firebal', 'much', ':)']]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["def naive_bayes_predict(tweet_list, logprior, loglikelihood):\n","    '''\n","    Input:\n","        tweet_list: a list of lists of words (processed tweets)\n","        logprior: a number\n","        loglikelihood: a dictionary of words mapping to numbers\n","    Output:\n","        predictions: a list of probabilities for each tweet in tweet_list\n","    '''\n","\n","    # initialize probability to zero\n","    p = 0\n","\n","    # add the logprior\n","    p += logprior\n","\n","    for word in tweet_list:\n","\n","        # check if the word exists in the loglikelihood dictionary\n","        if word in loglikelihood:\n","            # add the log likelihood of that word to the probability\n","            p += loglikelihood[word]\n","\n","    return p\n"],"metadata":{"id":"ecklmspfFLPY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving into a CSV file\n","lldata.to_csv('loglikelihood.csv', index=False)  # Set index=False to exclude the index from the file"],"metadata":{"id":"27Be6l_1TN8T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loglikelihood = lldata.set_index('Word')['log_likelihood'].to_dict()"],"metadata":{"id":"blj6qdujOJhv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","for key, value in loglikelihood.items():\n","    if count < 10:\n","        print(key, ':', value)\n","        count += 1\n","    else:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kW7fPCk1Ojim","executionInfo":{"status":"ok","timestamp":1714476453238,"user_tz":-300,"elapsed":8,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}},"outputId":"cb7c4816-0eed-4506-9525-894199ee78db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nice : 1.597009777301369\n","dave : 1.789381669948825\n",":d : 6.443342020106348\n","okay : 0.022940008705059904\n","son : 0.9139129325949251\n","4:13 : 0.6907693812807153\n","cant : -1.1009900879473398\n","sleep : -0.6845959093069852\n","bc : -1.63161833900951\n","insomnia : 0.6907693812807153\n"]}]},{"cell_type":"code","source":["def evaluate(ypred, ytrue):\n","    '''\n","    Input:\n","        ypred: a list of predicted values\n","        ytrue: a list of true labels\n","    Output:\n","        predictions: a list of predicted labels (0 for negative, 1 for positive)\n","        accuracy: accuracy of the predictions\n","    '''\n","    # Initialize an empty list to store predicted labels\n","    predictions = []\n","\n","    # Iterate over each predicted value in ypred\n","    for pred_value in ypred:\n","        # If the predicted value is greater than or equal to the threshold, classify as positive (1)\n","        if pred_value >= 0:\n","            predictions.append(1)\n","        # Otherwise, classify as negative (0)\n","        else:\n","            predictions.append(0)\n","\n","    # Calculate accuracy\n","    correct_predictions = sum(1 for pred, true in zip(predictions, ytrue) if pred == true)\n","    total_predictions = len(ytrue)\n","    accuracy = correct_predictions / total_predictions\n","\n","    return predictions, accuracy"],"metadata":{"id":"0YWqggyR96-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize an empty list to store predictions\n","ypred = []\n","\n","# Iterate over each tweet in the test_tweets list\n","for tweet in test_tweets:\n","    # Use the naive_bayes_predict function to get the prediction for the tweet\n","    prediction = naive_bayes_predict(tweet, logprior, loglikelihood)\n","    ypred.append(prediction)\n","\n","\n","result,acc = evaluate(ypred,test_labels)\n","print(acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLIYjIdtpD9e","outputId":"035dbd51-1bf7-4ac1-e917-1d498b2d6509","executionInfo":{"status":"ok","timestamp":1714476453726,"user_tz":-300,"elapsed":493,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.997\n"]}]},{"cell_type":"markdown","source":["### 6. On Unit Test"],"metadata":{"id":"ZtHLuA2ER0tl"}},{"cell_type":"code","source":["# New tweets to be added\n","tweets = [\n","    \"i am sad.\",\n","    \"feeling :(.\",\n","    \"i am happy.\",\n","    \":) moment.\"\n","]\n","\n","ytrue = [0,0,0,1,1]\n","ypred = []\n","\n","process_tweets = []\n","\n","# Process all tweets\n","for tweet in tweets:\n","    process_tweets.append(process_tweet(tweet))\n","\n","for tw in process_tweets:\n","  # Pass the array to the predict function\n","  ypred.append(naive_bayes_predict(tw, logprior, loglikelihood))\n","\n","result,acc = evaluate(ypred,ytrue)\n","\n","# Display the predicted labels\n","print(\"\\n Predicted LogLikehood :\",ypred)\n","print(\"\\n Predicted labels :\",result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIvSf_SpS3KW","outputId":"3f1586f8-9bb7-4369-9836-89606d83af42","executionInfo":{"status":"ok","timestamp":1714476453727,"user_tz":-300,"elapsed":4,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Predicted LogLikehood : [-3.030899895656212, -8.95807104342339, 2.0961119373713006, 6.933571992622917]\n","\n"," Predicted labels : [0, 0, 1, 1]\n"]}]}]}