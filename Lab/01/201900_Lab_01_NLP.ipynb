{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Logistic Regression\n","\n","Logistic Regression is a statistical method used for binary classification tasks, predicting the probability that an input belongs to one of two classes. Despite its name, it's a classification algorithm.\n","\n","  1. Model Representation: logâ¡(p1âˆ’p)=Î²0+Î²1X1+Î²2X2+...+Î²nXnlog(1âˆ’ppâ€‹)=Î²0â€‹+Î²1â€‹X1â€‹+Î²2â€‹X2â€‹+...+Î²nâ€‹Xnâ€‹\n","  2. Logistic Function (Sigmoid): p=11+eâˆ’(Î²0+Î²1X1+Î²2X2+...+Î²nXn)p=1+eâˆ’(Î²0â€‹+Î²1â€‹X1â€‹+Î²2â€‹X2â€‹+...+Î²nâ€‹Xnâ€‹)1â€‹\n","  3. Training: Estimate coefficients Î²0,Î²1,...,Î²nÎ²0â€‹,Î²1â€‹,...,Î²nâ€‹ using methods like maximum likelihood estimation on labeled data.\n","  4. Prediction: Calculate the probability of class membership using the trained model. If probability > 0.5, classify as positive class; else, negative class.\n","  5. Decision Boundary: Line separating classes determined by model coefficients. It's where predicted probability of positive class = 0.5.\n"],"metadata":{"id":"ntNdZlXErFPM"}},{"cell_type":"markdown","source":["### 1. Import Functions and Data"],"metadata":{"id":"VJxUeHnobMGX"}},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7kv4Gd5QPcN","outputId":"7ccaefca-49b0-4abf-f9ac-dcfc943929b9","executionInfo":{"status":"ok","timestamp":1714475831739,"user_tz":-300,"elapsed":3,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n","[nltk_data]   Package twitter_samples is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":35}],"source":["\n","import nltk # Python library for NLP\n","from nltk.corpus import twitter_samples # sample Twitter dataset from NLTK\n","import matplotlib.pyplot as plt # library for visualization\n","import random # pseudo-random number generator\n","\n","import re # library for regular expression operations\n","import string # for string operations\n","\n","from nltk.corpus import stopwords # module for stop words that come with NLTK\n","from nltk.stem import PorterStemmer # module for stemming\n","from nltk.tokenize import TweetTokenizer # module for tokenizing strings\n","\n","import csv\n","import numpy as np\n","import pandas as pd\n","from sklearn.utils import shuffle\n","\n","nltk.download('twitter_samples')\n","nltk.download('stopwords')\n"]},{"cell_type":"code","source":["\n","# select the set of positive and negative tweets\n","all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n","all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n","\n","# Save the tweets to a file\n","with open('positive_tweets.txt', 'w', encoding='utf-8') as f:\n","    f.write('\\n'.join(all_positive_tweets))\n","\n","with open('negative_tweets.txt', 'w', encoding='utf-8') as f:\n","    f.write('\\n'.join(all_negative_tweets))\n"],"metadata":{"id":"GZRStDw9Rc6T","executionInfo":{"status":"ok","timestamp":1714475832451,"user_tz":-300,"elapsed":713,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Randomly select three positive tweets\n","random_positive_tweets = random.sample(all_positive_tweets, 3)\n","\n","# Randomly select three negative tweets\n","random_negative_tweets = random.sample(all_negative_tweets, 3)\n","\n","print(\"Randomly selected positive tweets:\")\n","for tweet in random_positive_tweets:\n","    print(tweet)\n","\n","print(\"\\nRandomly selected negative tweets:\")\n","for tweet in random_negative_tweets:\n","    print(tweet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFd2nSubZu5U","outputId":"147375fd-0b18-4ee8-ac31-11a5b5362531","executionInfo":{"status":"ok","timestamp":1714475832451,"user_tz":-300,"elapsed":5,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Randomly selected positive tweets:\n","@MonicaBhambhani @Equinox my pleasure doll! Thank you for your wonderful energy in class! :)\n","@DomSequitur tired. But fine :) you??\n","@stuck_for_ideas Thanks for the shout out guys :)\n","\n","Randomly selected negative tweets:\n","@sophiabxsh no Idk if I wanna watch the episode now :(\n","@junhuiass IT'S BEEN YEARS SINCE I HAVE BEEN IN A ZOO AND IT'S ONLY ON FIELDTRIPS SO NO TIME TO TOUCH :(((\n","their reactions :(((((\n"]}]},{"cell_type":"code","source":["\n","print(len(all_positive_tweets),all_positive_tweets[0])\n","print(len(all_negative_tweets),all_negative_tweets[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsLCfNhNRqYV","outputId":"b6f99bb5-5d7f-4e18-deb0-0558465de2be","executionInfo":{"status":"ok","timestamp":1714475832452,"user_tz":-300,"elapsed":4,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["5000 #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n","5000 hopeless for tmr :(\n"]}]},{"cell_type":"markdown","source":["### 2. Preprocessing"],"metadata":{"id":"0jHBlwOtWOwi"}},{"cell_type":"code","source":["\n","def process_tweet(tweet):\n","\n","  \"\"\"Process tweet function.\n","  Input:\n","  tweet: a string containing a tweet\n","  Output:\n","  tweets_clean: a list of words containing the processed tweet\n","  \"\"\"\n","  stemmer = PorterStemmer( )\n","  stopwords_english = stopwords.words('english')\n","  # remove stock market tickers like $GE\n","  tweet = re.sub(r'\\$\\w*', '', tweet)\n","  # remove old style retweet text \"RT\"\n","  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n","  # remove hyperlinks\n","  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n","\n","  # only removing the hash # sign from the word\n","  tweet = re.sub(r'#', '', tweet)\n","  # tokenize tweets\n","  tokenizer = TweetTokenizer(preserve_case=False,\n","  strip_handles=True, reduce_len=True)\n","\n","  tweet_tokens = tokenizer.tokenize(tweet)\n","\n","  tweets_clean = []\n","  for word in tweet_tokens:\n","    if (word not in stopwords_english and # remove stopwords\n","      word not in string.punctuation): # remove punctuation\n","\n","      # tweets_clean.append(word)\n","      stem_word = stemmer.stem(word) # stemming word\n","      tweets_clean.append(stem_word)\n","\n","  return tweets_clean"],"metadata":{"id":"r4cMKFzkZJUE","executionInfo":{"status":"ok","timestamp":1714475832452,"user_tz":-300,"elapsed":3,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["\n","# Initializing lists to store processed positive and negative tweets\n","pro_pos_tw = []\n","pro_neg_tw = []\n","\n","# Processing each tweet in the list of positive tweets\n","for tweet in all_positive_tweets:\n","    # Applying the process_tweet function to preprocess the tweet\n","    pro_pos_tw.append(process_tweet(tweet))\n","\n","# Processing each tweet in the list of negative tweets\n","for tweet in all_negative_tweets:\n","    # Applying the process_tweet function to preprocess the tweet\n","    pro_neg_tw.append(process_tweet(tweet))\n","\n","# Printing the number of processed positive tweets and an example of the first processed positive tweet\n","print(\"Number of processed positive tweets:\", len(pro_pos_tw))\n","print(\"Example of a processed positive tweet:\", pro_pos_tw[0])\n","\n","# Printing the number of processed negative tweets and an example of the first processed negative tweet\n","print(\"Number of processed negative tweets:\", len(pro_neg_tw))\n","print(\"Example of a processed negative tweet:\", pro_neg_tw[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JN319jpSwq-","outputId":"af2dfcee-a062-4a6b-f77b-c4d7f4f0741b","executionInfo":{"status":"ok","timestamp":1714475838370,"user_tz":-300,"elapsed":5920,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of processed positive tweets: 5000\n","Example of a processed positive tweet: ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n","Number of processed negative tweets: 5000\n","Example of a processed negative tweet: ['hopeless', 'tmr', ':(']\n"]}]},{"cell_type":"code","source":["\n","# Shuffle positive and negative tweets\n","random.shuffle(pro_pos_tw)\n","random.shuffle(pro_neg_tw)\n","\n","# Select 4000 random positive and negative tweets for training\n","train_pos_tw = pro_pos_tw[:4000]\n","train_neg_tw = pro_neg_tw[:4000]\n","\n","# Select 1000 random positive and negative tweets for testing\n","test_pos_tw = pro_pos_tw[4000:]\n","test_neg_tw = pro_neg_tw[4000:]\n","\n","# Combine training and testing tweets\n","train_tweets = train_pos_tw + train_neg_tw\n","test_tweets = test_pos_tw + test_neg_tw\n","\n","# Create labels\n","train_labels = [1] * len(train_pos_tw) + [0] * len(train_neg_tw)\n","test_labels = [1] * len(test_pos_tw) + [0] * len(test_neg_tw)\n","\n","# Checking sizes of training and testing sets\n","print(\"Training set size:\", len(train_tweets))\n","print(\"Testing set size:\", len(test_tweets))\n","\n","# Checking distribution of labels in training and testing sets\n","from collections import Counter\n","print(\"Training set label distribution:\", Counter(train_labels))\n","print(\"Testing set label distribution:\", Counter(test_labels))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlegA9GlUbGo","outputId":"0397db9e-e969-4dcb-d48f-bf5c23c14d24","executionInfo":{"status":"ok","timestamp":1714475838370,"user_tz":-300,"elapsed":19,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set size: 8000\n","Testing set size: 2000\n","Training set label distribution: Counter({1: 4000, 0: 4000})\n","Testing set label distribution: Counter({1: 1000, 0: 1000})\n"]}]},{"cell_type":"code","source":["len(train_tweets),len(train_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rh4j3H1AqcYm","outputId":"b5f5cc6b-93cb-40e7-90be-62ea67388d33","executionInfo":{"status":"ok","timestamp":1714475838370,"user_tz":-300,"elapsed":15,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8000, 8000)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["\n","print(train_tweets[10])\n","print(train_labels[10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BGWO1HKqem3","outputId":"33501543-64b7-4fd6-bcf8-0d07070ba7fe","executionInfo":{"status":"ok","timestamp":1714475838370,"user_tz":-300,"elapsed":14,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["['follow']\n","1\n"]}]},{"cell_type":"code","source":["count=0\n","for l,t in zip(train_labels,train_tweets):\n","  print(l,t)\n","\n","  count += 1\n","  if(count>10):\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vecrLl0ZVbgY","outputId":"467cf31d-337c-4c34-e590-b7040a2c0f71","executionInfo":{"status":"ok","timestamp":1714475838370,"user_tz":-300,"elapsed":11,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["1 ['hi', 'emma', ':-)', 'ask', 'bellybutton', 'inni', 'outi']\n","1 [\"he'\", 'twitch', \"he'\", 'got', 'twitch', ':-)']\n","1 [':)', 'beauti']\n","1 ['males', ':d']\n","1 ['beauti', ':)', 'got', 'blackfli', 'courgett', 'flower', 'year', '..', 'idea', 'hope', 'wont', 'affect', 'fruit']\n","1 ['snapchat', 'jennyjean', '22', 'snapchat', 'kikmeboy', 'model', 'french', 'kikchat', 'sabadodeganarseguidor', 'sexysasunday', ':)']\n","1 ['sept', '4th', 'rudramadevi', 'anushka', 'gunashekar', 'sir', ':)']\n","1 ['name', 'coupl', 'yet', 'tomhiddleston', 'elizabetholsen', 'yaytheylookgreat', ':)']\n","1 [\"i'm\", 'glow', 'morn', 'yayyy', ':)', 'happi', 'friday', 'xx']\n","1 ['oh', 'happi', 'hear', ':)', 'love', 'day', 'cl']\n","1 ['follow']\n"]}]},{"cell_type":"markdown","source":["### 3. Sigmoid Function"],"metadata":{"id":"KKyCfMtWAlo9"}},{"cell_type":"code","source":["\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","def cost_function(X, y, theta):\n","    m = len(y)\n","    h = sigmoid(np.dot(X, theta))\n","    cost = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n","    return cost\n"],"metadata":{"id":"E6tgs5KrApdi","executionInfo":{"status":"ok","timestamp":1714475838370,"user_tz":-300,"elapsed":9,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["### 4. Gradient Descent"],"metadata":{"id":"CBH9xQuaBNkq"}},{"cell_type":"code","source":["\n","def gradient(X, y, theta):\n","    m = len(y)\n","    h = sigmoid(np.dot(X, theta))\n","    grad = (1 / m) * np.dot(X.T, (h - y))\n","    return grad\n","\n","def gradient_descent(X, y, theta, alpha=0.01, iterations=1000):\n","    m = len(y)\n","    cost_history = []\n","\n","    for _ in range(iterations):\n","        theta -= alpha * gradient(X, y, theta)\n","        cost = cost_function(X, y, theta)\n","        cost_history.append(cost)\n","\n","    return theta, cost_history\n"],"metadata":{"id":"lZR-kgmcBM6G","executionInfo":{"status":"ok","timestamp":1714475838372,"user_tz":-300,"elapsed":10,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["### 5. Extract Feature"],"metadata":{"id":"WPyrn42aa75w"}},{"cell_type":"code","source":["\n","def build_freqs(tweets, ys):\n","  \"\"\"Build frequencies.\n","  Input:\n","  tweets: a list of tweets\n","  ys: an m x 1 array with the sentiment label of each tweet\n","  (either 0 or 1)\n","  Output:\n","  freqs: a dictionary mapping each (word, sentiment) pair to its\n","  frequency\n","  \"\"\"\n","  # Convert np array to list since zip needs an iterable.\n","  # The squeeze is necessary, or the list ends up with one element.\n","  # Also note that this is just a NOP if ys is already a list.\n","  #yslist = np.squeeze(ys).tolist()\n","\n","  # Start with an empty dictionary and populate it by looping over all tweets and over all processed words in each tweet.\n","  freqs = { }\n","\n","  for y, tweet in zip(ys, tweets):\n","    for word in tweet:\n","      pair = (word, y)\n","      if pair in freqs:\n","        freqs[pair] += 1\n","      else:\n","        freqs[pair] = 1\n","\n","  return freqs\n"],"metadata":{"id":"GXyho0vhX-Jb","executionInfo":{"status":"ok","timestamp":1714475838372,"user_tz":-300,"elapsed":10,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["freq = build_freqs(train_tweets+test_tweets,train_labels+test_labels)"],"metadata":{"id":"INHUEJtfcWrb","executionInfo":{"status":"ok","timestamp":1714475838372,"user_tz":-300,"elapsed":10,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["print(len(freq),type(freq))\n","\n","count = 0\n","for key, value in freq.items():\n","    if count < 10:\n","        print(key, ':', value)\n","        count += 1\n","    else:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfTmzwfEe3CU","outputId":"25e2558e-8b97-498e-e3d2-76dca0a11089","executionInfo":{"status":"ok","timestamp":1714475838372,"user_tz":-300,"elapsed":10,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["13065 <class 'dict'>\n","('hi', 1) : 173\n","('emma', 1) : 2\n","(':-)', 1) : 692\n","('ask', 1) : 37\n","('bellybutton', 1) : 5\n","('inni', 1) : 4\n","('outi', 1) : 4\n","(\"he'\", 1) : 11\n","('twitch', 1) : 5\n","('got', 1) : 69\n"]}]},{"cell_type":"code","source":["\n","def extract_features(tweet_words, frequency_table):\n","\n","    \"\"\"\n","    Count sentiment based on tweet words and a frequency table.\n","\n","    Parameters:\n","        tweet_words (list): List of words in the tweet.\n","        frequency_table (dict): Dictionary containing word-sentiment score pairs and their frequencies.\n","        label (int): Label for the sentiment (0 for negative, 1 for positive).\n","\n","    Returns:\n","        tuple: A tuple containing positive count, negative count, and label.\n","    \"\"\"\n","\n","    # Initialize counts for positive and negative words\n","    positive_count = 0\n","    negative_count = 0\n","\n","    # Iterate over words in the tweet\n","    for word in tweet_words:\n","        # Check if the word is in the frequency table\n","        for key, value in frequency_table.items():\n","            if word == key[0]:\n","                # Increment positive or negative count based on the sentiment score\n","                if key[1] == 1:\n","                    positive_count += value\n","                if key[1] == 0:\n","                    negative_count += value\n","\n","    return 1,positive_count,negative_count\n"],"metadata":{"id":"capkfe6okmX9","executionInfo":{"status":"ok","timestamp":1714475838372,"user_tz":-300,"elapsed":7,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["\n","def process_and_save_features(tweets, labels, frequency_table, output_filename):\n","    \"\"\"\n","    Calculate sentiment counts for each tweet and save the results to a CSV file.\n","\n","    Parameters:\n","    - tweets (list): A list of tweets.\n","    - labels (list): A list of corresponding labels for the tweets.\n","    - frequency_table (dict): A dictionary containing word-sentiment score pairs and their frequencies.\n","    - output_filename (str): The name of the output CSV file.\n","\n","    Returns:\n","    None\n","    \"\"\"\n","    sentiment_counts = []\n","\n","    # Iterate over each tweet and label\n","    for tweet, label in zip(tweets, labels):\n","\n","      # Calculate sentiment counts for the tweet\n","      bias, positive_count, negative_count = extract_features(tweet, frequency_table)\n","      # Append the results to the list\n","      sentiment_counts.append([bias, positive_count, negative_count, label])\n","\n","    # Write sentiment counts to CSV file\n","    with open(output_filename, 'w', newline='', encoding='utf-8') as csvfile:\n","        csv_writer = csv.writer(csvfile)\n","        # Write header\n","        csv_writer.writerow(['Bias', 'Positive_Count', 'Negative_Count', 'Label'])\n","        # Write data\n","        csv_writer.writerows(sentiment_counts)\n"],"metadata":{"id":"bW5wvJif1swt","executionInfo":{"status":"ok","timestamp":1714475838372,"user_tz":-300,"elapsed":7,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["len(train_tweets),len(train_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ddF0q-nfDYY","outputId":"bb6fe740-25dc-4c60-8dde-aa2bb1301f18","executionInfo":{"status":"ok","timestamp":1714475838372,"user_tz":-300,"elapsed":7,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8000, 8000)"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["\n","process_and_save_features(train_tweets,train_labels,freq,\"train.csv\")\n","process_and_save_features(test_tweets,test_labels,freq,\"test.csv\")\n"],"metadata":{"id":"9zTCTttd1_ey","executionInfo":{"status":"ok","timestamp":1714475935047,"user_tz":-300,"elapsed":96681,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["### 6. Train"],"metadata":{"id":"VgdDGCEC5dSA"}},{"cell_type":"code","source":["\n","# Load train and test data\n","train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","\n","# Shuffle train and test data\n","#train = shuffle(train)\n","#test = shuffle(test)\n","\n","# Display the shape of train and test data\n","print(\"Shape of train data:\", train.shape)\n","print(\"Shape of test data:\", test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKat7Jfo5fTP","outputId":"2f6401ec-050e-4573-c5fe-7d15a2796353","executionInfo":{"status":"ok","timestamp":1714475935048,"user_tz":-300,"elapsed":19,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of train data: (8000, 4)\n","Shape of test data: (2000, 4)\n"]}]},{"cell_type":"code","source":["\n","# Count of records with label 0 and 1 in training data\n","train_label_counts = train['Label'].value_counts()\n","print(\"Training data label counts:\")\n","print(train_label_counts)\n","\n","# Count of records with label 0 and 1 in test data\n","test_label_counts = test['Label'].value_counts()\n","print(\"\\nTest data label counts:\")\n","print(test_label_counts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjE98ZSt9UzC","outputId":"8a61c4b1-2d84-4768-e1ec-c7dfe235c6f2","executionInfo":{"status":"ok","timestamp":1714475935049,"user_tz":-300,"elapsed":15,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data label counts:\n","Label\n","1    4000\n","0    4000\n","Name: count, dtype: int64\n","\n","Test data label counts:\n","Label\n","1    1000\n","0    1000\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"LYRjlcMxDFKK","outputId":"a046b747-93cd-4fc2-b3e4-c799018fa5d6","executionInfo":{"status":"ok","timestamp":1714475935049,"user_tz":-300,"elapsed":12,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Bias  Positive_Count  Negative_Count  Label\n","0        1             917              65      1\n","1        1             793             150      1\n","2        1            3618              13      1\n","3        1             630               0      1\n","4        1            4043             396      1\n","...    ...             ...             ...    ...\n","7995     1             264            4962      0\n","7996     1             595            5215      0\n","7997     1             173            4757      0\n","7998     1             724            5169      0\n","7999     1             440            5219      0\n","\n","[8000 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-dc2aa26d-e370-48fe-8eca-af567e8c2fb6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Bias</th>\n","      <th>Positive_Count</th>\n","      <th>Negative_Count</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>917</td>\n","      <td>65</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>793</td>\n","      <td>150</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3618</td>\n","      <td>13</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>630</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>4043</td>\n","      <td>396</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7995</th>\n","      <td>1</td>\n","      <td>264</td>\n","      <td>4962</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7996</th>\n","      <td>1</td>\n","      <td>595</td>\n","      <td>5215</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7997</th>\n","      <td>1</td>\n","      <td>173</td>\n","      <td>4757</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7998</th>\n","      <td>1</td>\n","      <td>724</td>\n","      <td>5169</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7999</th>\n","      <td>1</td>\n","      <td>440</td>\n","      <td>5219</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8000 rows Ã— 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc2aa26d-e370-48fe-8eca-af567e8c2fb6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dc2aa26d-e370-48fe-8eca-af567e8c2fb6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dc2aa26d-e370-48fe-8eca-af567e8c2fb6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-26388148-60b0-4419-aabf-59d79e0e2ac1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26388148-60b0-4419-aabf-59d79e0e2ac1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-26388148-60b0-4419-aabf-59d79e0e2ac1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train","summary":"{\n  \"name\": \"train\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"Bias\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Positive_Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1972,\n        \"min\": 0,\n        \"max\": 42824,\n        \"num_unique_values\": 2286,\n        \"samples\": [\n          7500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Negative_Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2539,\n        \"min\": 0,\n        \"max\": 27723,\n        \"num_unique_values\": 1936,\n        \"samples\": [\n          614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["\n","# Prepare data\n","X_train = train.drop(columns=['Label']).values\n","y_train = train['Label'].values.reshape(-1, 1)\n","\n","X_test = test.drop(columns=['Label']).values\n","y_test = test['Label'].values.reshape(-1, 1)\n"],"metadata":{"id":"1JKdrXXKGMBB","executionInfo":{"status":"ok","timestamp":1714475935049,"user_tz":-300,"elapsed":10,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["\n","# Initialize parameters\n","theta_initial = np.zeros((X_train.shape[1], 1))\n","\n","# Train the model\n","theta, cost_history = gradient_descent(X_train, y_train, theta_initial)\n","\n","# Evaluate the model\n","final_train_cost = cost_history[-1]\n","print(\"\\n Final training cost:\", final_train_cost)\n","\n","# Predict on test data\n","predicted_probabilities = sigmoid(np.dot(X_test, theta))\n","predicted_labels = (predicted_probabilities >= 0.5).astype(int)\n","\n","# Calculate accuracy\n","accuracy = np.mean(predicted_labels == y_test)\n","print(\"\\n Accuracy on test set:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pB7d1AX3DuDG","outputId":"5c0aa6b6-e4cd-4501-d8ec-762abc8fc70f","executionInfo":{"status":"ok","timestamp":1714475936431,"user_tz":-300,"elapsed":1392,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-45-da14e7e5d29c>:2: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(-z))\n","<ipython-input-45-da14e7e5d29c>:7: RuntimeWarning: divide by zero encountered in log\n","  cost = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n","<ipython-input-45-da14e7e5d29c>:7: RuntimeWarning: invalid value encountered in multiply\n","  cost = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Final training cost: nan\n","\n"," Accuracy on test set: 0.994\n"]}]},{"cell_type":"markdown","source":["### 7. Test"],"metadata":{"id":"z4UT3YMrNp4j"}},{"cell_type":"code","source":["\n","def predict(X, theta):\n","    probabilities = sigmoid(np.dot(X, theta))\n","    return probabilities\n"],"metadata":{"id":"xAZGbvMRokaX","executionInfo":{"status":"ok","timestamp":1714475936432,"user_tz":-300,"elapsed":25,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["print(theta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecklmspfFLPY","outputId":"a561c195-a858-42cd-87e3-ba59785ddac5","executionInfo":{"status":"ok","timestamp":1714475936432,"user_tz":-300,"elapsed":23,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["[[  0.02213753]\n"," [ 13.00565291]\n"," [-12.37915871]]\n"]}]},{"cell_type":"code","source":["# Predict probabilities for the test data\n","probabilities = predict(X_test, theta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLIYjIdtpD9e","outputId":"34981b09-93b4-4eb0-9c40-c4c1eee28a64","executionInfo":{"status":"ok","timestamp":1714475936432,"user_tz":-300,"elapsed":20,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":61,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-45-da14e7e5d29c>:2: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(-z))\n"]}]},{"cell_type":"markdown","source":["### 8. Evaluate"],"metadata":{"id":"tXXVyM7do1im"}},{"cell_type":"code","source":["# Convert probabilities to binary predictions\n","predictions = (probabilities >= 0.5).astype(int)\n","\n","# Evaluate accuracy\n","accuracy = np.mean(predictions == y_test)\n","print(\"Accuracy on test data:\", accuracy, \"\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iq3Val69GG8Z","outputId":"b81cb50a-71ee-43a7-ca30-ce2740452cd1","executionInfo":{"status":"ok","timestamp":1714475936432,"user_tz":-300,"elapsed":18,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test data: 0.994 \n","\n"]}]},{"cell_type":"code","source":["# Calculate TP, FP, FN, TN\n","TP = np.sum((predictions == 1) & (y_test == 1))\n","FP = np.sum((predictions == 1) & (y_test == 0))\n","FN = np.sum((predictions == 0) & (y_test == 1))\n","TN = np.sum((predictions == 0) & (y_test == 0))\n","\n","# Calculate precision, recall, and F-measure\n","precision = TP / (TP + FP)\n","recall = TP / (TP + FN)\n","f_measure = 2 * precision * recall / (precision + recall)\n","\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F-measure:\", f_measure)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PMpbVkgNt-O","outputId":"3f853c58-430c-40f9-839d-221d925b531c","executionInfo":{"status":"ok","timestamp":1714475936433,"user_tz":-300,"elapsed":17,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.9930139720558883\n","Recall: 0.995\n","F-measure: 0.994005994005994\n"]}]},{"cell_type":"markdown","source":["### 9. Error Analysis"],"metadata":{"id":"zi4-sGB3R70-"}},{"cell_type":"markdown","source":["**Extracting Features and Simplifying Classification in Sentiment Analysis**\n","\n","In sentiment analysis, the extracted features reveal that tweets with a higher positive count are categorized as positive, while others are deemed negative. Therefore, there's no necessity for computing the sigmoid function; a simple relational operator can achieve the same outcome. Additionally, utilizing thesauruses and language mapping can enhance the relevance of words to positive or negative classes, facilitating the removal of neutral words.\n","\n","1. **Eliminating Sigmoid Computation**: By leveraging the insight that tweets with a greater positive count are already indicative of positive sentiment, there's no requirement for complex sigmoid computations. Simplifying the classification process with basic relational operators streamlines the sentiment analysis task.\n","\n","2. **Enhancing Word Relevance**: Incorporating thesauruses and language mapping techniques aids in refining the relevance of words to positive or negative sentiment classes. This approach helps in filtering out neutral words, thereby improving the accuracy and efficiency of sentiment analysis algorithms.\n"],"metadata":{"id":"C6TttqC4lWS1"}},{"cell_type":"code","source":["\n","# Filter misclassified tweets\n","misclassified_tweets = test[predictions.flatten() != y_test.flatten()]\n","\n","# Display misclassified tweets\n","print(\"Misclassified tweets:\")\n","print(misclassified_tweets)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uJ9t96vQejJ","outputId":"d25552ee-0773-4821-e1e4-0702aa372ee5","executionInfo":{"status":"ok","timestamp":1714475936433,"user_tz":-300,"elapsed":14,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Misclassified tweets:\n","      Bias  Positive_Count  Negative_Count  Label\n","21       1             102             115      1\n","143      1             264             395      1\n","221      1             589             726      1\n","568      1             264             395      1\n","726      1             264             395      1\n","1003     1             131              98      0\n","1272     1             267             251      0\n","1316     1             903             922      0\n","1554     1             208             119      0\n","1827     1              66              54      0\n","1939     1             416             180      0\n","1971     1             499             423      0\n"]}]},{"cell_type":"code","source":["\n","# Get indices of misclassified tweets\n","misclassified_indices = misclassified_tweets.index.tolist()\n","\n","for i in range(len(misclassified_indices)):\n","  print(test_tweets[misclassified_indices[i]])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWUm541AQq01","outputId":"2de0acab-b863-4198-c848-75b405a38ec4","executionInfo":{"status":"ok","timestamp":1714475936433,"user_tz":-300,"elapsed":12,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}}},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["['brief', 'introduct', '2', 'earliest', 'histori', 'indian', 'subcontin', 'even', 'bfr', 'maurya']\n","[\"i'm\", 'play', 'brain', 'dot', 'braindot']\n","['omg', \"can't\", 'tell', 'say', ':p', \"can't\", 'wait', 'know', 'â¤', 'ï¸']\n","[\"i'm\", 'play', 'brain', 'dot', 'braindot']\n","[\"i'm\", 'play', 'brain', 'dot', 'braindot']\n","['beast', 'next', 'week']\n","['like', 'video']\n","['midland', 'ye', 'thank', 'depress', 'weather', 'forecast', 'word', 'rain', 'mention', 'sever', 'time', ':-(']\n","['corbyn', 'must', 'understand', \"labour'\", 'new', 'member', 'chang', \"party'\", 'fortun']\n","['laomma', 'design', 'kebaya', 'wed', 'dress', 'bandung', 'indonesia', 'line', 'laomma', '7df89150', 'whatsapp', '62', '08962464174', '7', 'instagram', 'laomma_coutur']\n","['shake', 'head', 'repeatedli', 'nu-uh', 'jace', 'love', 'mostest']\n","['twitter', 'help', 'center', '39', 'follow', 'peopl']\n"]}]},{"cell_type":"markdown","source":["### 10. On Unit Test"],"metadata":{"id":"ZtHLuA2ER0tl"}},{"cell_type":"code","source":["\n","# New tweets to be added\n","tweets = [\n","    \"i am sad.\",\n","    \"feeling :(.\",\n","    \"i am happy.\",\n","    \":) moment.\"\n","]\n","\n","process_tweets = []\n","\n","# Process all tweets\n","for tweet in tweets:\n","    process_tweets.append(process_tweet(tweet))\n","\n","for tw in process_tweets:\n","    print(tw)\n","\n","sentiment_counts = []\n","\n","# Extract features for all processed tweets\n","for tweet in process_tweets:\n","    bias, positive_count, negative_count = extract_features(tweet, freq)\n","    sentiment_counts.append([bias, positive_count, negative_count])\n","\n","print(\"\\n Featured Extracted : \", sentiment_counts)\n","\n","# Convert the list of lists to a NumPy array\n","X_new = np.array(sentiment_counts)\n","\n","# Pass the array to the predict function\n","probabilities_new = predict(X_new, theta)\n","\n","print(\"\\n Prob : \", probabilities_new)\n","\n","# Convert probabilities to binary predictions\n","predictions_new = (probabilities_new >= 0.5).astype(int)\n","\n","# Display the predicted labels\n","print(\"\\n Predicted labels for new data :\", predictions_new.flatten())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIvSf_SpS3KW","executionInfo":{"status":"ok","timestamp":1714475936433,"user_tz":-300,"elapsed":10,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"01537056024676725507"}},"outputId":"fdd915e1-38c3-4aa6-9ae6-fd5ef7c7b3c3"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["['sad']\n","['feel', ':(']\n","['happi']\n","[':)', 'moment']\n","\n"," Featured Extracted :  [[1, 5, 123], [1, 47, 4729], [1, 211, 25], [1, 3580, 16]]\n","\n"," Prob :  [[0.]\n"," [0.]\n"," [1.]\n"," [1.]]\n","\n"," Predicted labels for new data : [0 0 1 1]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-45-da14e7e5d29c>:2: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(-z))\n"]}]},{"cell_type":"markdown","source":["#### Role of Special Symbols in Sentiment Analysis\n","\n","In sentiment analysis, special symbols and punctuation marks play a vital role in determining the sentiment of a text. Here are some key points to consider:\n","\n","1. **Emoticons and Emoji:** Emoticons such as \":)\", \":(\", and emojis like ðŸ˜Š, ðŸ˜¢ directly convey emotions and significantly influence sentiment classification. For example, \":)\" typically indicates happiness or positivity, while \":(\" indicates sadness or negativity.\n","\n","2. **Punctuation Marks:** Punctuation marks such as exclamation marks (!), question marks (?), and ellipses (...) provide contextual cues for sentiment analysis. Multiple exclamation marks might indicate excitement, while a question mark might suggest uncertainty.\n","\n","3. **Capitalization:** The use of uppercase letters can convey emphasis or heightened emotion, impacting sentiment analysis results.\n","\n","4. **Repeating Characters:** Repeated characters, like \"soooo\" or \"loooove,\" emphasize the intensity of an emotion, influencing sentiment analysis by amplifying the sentiment conveyed.\n","\n","5. **Sarcasm and Irony:** Special symbols and punctuation marks are often used to convey sarcasm or irony, challenging sentiment analysis due to the disparity between literal meaning and intended sentiment.\n","\n","6. **Negation:** Words like \"not\" or phrases like \"not good\" can reverse sentiment. Understanding negation context is crucial for accurate sentiment analysis.\n","\n","7. **Hashtags and Mentions:** In social media sentiment analysis, hashtags (#) and mentions (@) provide context about topics or entities discussed, enhancing sentiment classification accuracy.\n","\n","In summary, special symbols and punctuation marks carry rich contextual information that significantly impacts sentiment analysis. Incorporating these elements into sentiment analysis models improves their ability to accurately interpret and classify text sentiment.\n"],"metadata":{"id":"uNp6FAcDVcI1"}}]}