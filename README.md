# Machine Learning and NLP Notes


## Table of Contents


### 1. Logistic Regression
   - 1.1 Model Representation
   - 1.2 Logistic Function (Sigmoid)
   - 1.3 Training
   - 1.4 Prediction
   - 1.5 Decision Boundary


### 2. Naive Bayes
   - 2.1 Bayes' Theorem
   - 2.2 Log Likelihood


### 3. N-grams
   - 3.1 Definition
   - 3.2 Applications
     - 3.2.1 Language Modeling
     - 3.2.2 Text Prediction and Generation
     - 3.2.3 Information Retrieval
     - 3.2.4 Spell Checking and Correction
     - 3.2.5 Sentiment Analysis
     - 3.2.6 Named Entity Recognition (NER)


### 4. LSTM and Attention Mechanism
   - 4.1 LSTM Networks
   - 4.2 Attention Mechanism
     - 4.2.1 Score Calculation
     - 4.2.2 Attention Weights
     - 4.2.3 Context Vector


### 5. Text Generation with HuggingFace
   - 5.1 Greedy Search
   - 5.2 Beam Search
   - 5.3 Top-K Sampling
   - 5.4 Top-p (Nucleus) Sampling


### 6. Summarization with HuggingFace

  - 5.1 Greedy Search
  - 5.2 Beam Search
  - 5.3 Top-K Sampling
  - 5.4 Top-p (Nucleus) Sampling

## Resources

 - [Natural Language Processing in Action - Hobson Lane, Cole Howard, Hannes Max Hapke](https://github.com/MHM-Rajpoot/Natural-Language-Processing/blob/main/meta/Natural%20Language%20Processing%20in%20Action%20-%20Hobson%20Lane%2C%20Cole%20Howard%2C%20Hannes%20Max%20Hapke.pdf)
 - [Natural Language Processing with PyTorch - Delip Rao & Brian McMahan](https://github.com/MHM-Rajpoot/Natural-Language-Processing/blob/main/meta/Natural%20Language%20Processing%20with%20PyTorch%20-%20Delip%20Rao%20%26%20Brian%20McMahan.pdf)

## Getting Started

To explore these notes, simply clone this repository or download the contents.

